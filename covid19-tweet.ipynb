{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv\n/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv',encoding = 'latin_1')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test= pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv',encoding='latin_1')","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nimport re , string,unicodedata\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom string import punctuation\nimport keras\nfrom keras.models import Sequential\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.drop_duplicates(inplace=True)\ndata_test.drop_duplicates(inplace=True)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.dropna(inplace=True)\ndata_train.dropna(inplace=True)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_sent(sentiment):\n    if sentiment == \"Extremly Positive\":\n        return \"Positive\"\n    elif sentiment == \"Extremely Negative\":\n        return \"Negative Sentiment\"\n    elif sentiment == \"Positive\":\n        return \"Positive\"\n    elif sentiment == \"Negative Sentiment\":\n        return \"Negative Sentiment\"\n    else:\n        return 'Neutral'\n    ","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train['Sentiment']=data_train['Sentiment'].apply(lambda x:change_sent(x))\ndata_test['Sentiment']=data_test['Sentiment'].apply(lambda x:change_sent(x))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_word = stopwords.words('english')","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_clean(text):\n    text = re.sub(r'http\\S+',\" \",text)#remove url\n    text = re.sub(r'@\\w+',' ',text)#remove mentions\n    text = re.sub(r'#\\w+',' ',text)#remove hastags\n    text = re.sub(r'\\d+',' ' , text)#remove degits\n    text = re.sub('r<.*?>',' ',text)#remove tags\n    \n    text= text.split()\n    text = \" \".join([word for word in text if not word in stop_word])\n    \n    return text","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train['OriginalTweet']=data_train[\"OriginalTweet\"].apply(lambda x:text_clean(x))\ndata_test['OriginalTweet']=data_test[\"OriginalTweet\"].apply(lambda x:text_clean(x))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = data_train.iloc[:,4:]\ntest_df = data_test.iloc[:,4:]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = {\"Neutral\":0, \"Positive\":1,\"Negative Sentiment\":2}","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Sentiment']=train_df['Sentiment'].map(l)\ntest_df['Sentiment']=test_df['Sentiment'].map(l)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train_df['OriginalTweet'].copy()\ny_train = train_df['Sentiment'].copy()\n\nx_test = test_df['OriginalTweet'].copy()\ny_test = test_df['Sentiment'].copy()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = np.max(x_train.apply(lambda x : len(x)))","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(x_train)\nvocab_length = len(tokenizer.word_index)+1\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=pad_sequences(x_train,maxlen=max_len,padding='post')\nx_test = pad_sequences(x_test,maxlen=max_len,padding='post')","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 16","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= tf.keras.Sequential()\nmodel.add(tf.keras.layers.Embedding(vocab_length,embedding_dim,input_length=max_len))\nmodel.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256,return_sequences=True)))\n\nmodel.add(tf.keras.layers.GlobalAveragePooling1D())\n#model.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(64,activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.4))\nmodel.add(tf.keras.layers.Dense(3,activation='softmax'))\n#opt = tf.keras.optimizers.Adam(learning_rate=0.01)\nmodel.compile(loss=\"categorical_crossentropy\",optimizer =\"Adam\",metrics=[\"accuracy\"])","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":22,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 286, 16)           508144    \n_________________________________________________________________\nbidirectional (Bidirectional (None, 286, 512)          420864    \n_________________________________________________________________\nglobal_average_pooling1d (Gl (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                32832     \n_________________________________________________________________\ndropout (Dropout)            (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 195       \n=================================================================\nTotal params: 962,035\nTrainable params: 962,035\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = to_categorical(y_test,3)\ny_train = to_categorical(y_train,3)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train,y_train,epochs = 10,validation_data = (x_test,y_test))","execution_count":24,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n1018/1018 [==============================] - 42s 41ms/step - loss: 0.9173 - accuracy: 0.5893 - val_loss: 0.8195 - val_accuracy: 0.6184\nEpoch 2/10\n1018/1018 [==============================] - 42s 41ms/step - loss: 0.7579 - accuracy: 0.6395 - val_loss: 0.7678 - val_accuracy: 0.6538\nEpoch 3/10\n1018/1018 [==============================] - 42s 41ms/step - loss: 0.6667 - accuracy: 0.6738 - val_loss: 0.6824 - val_accuracy: 0.6953\nEpoch 4/10\n1018/1018 [==============================] - 42s 41ms/step - loss: 0.5114 - accuracy: 0.7712 - val_loss: 0.6698 - val_accuracy: 0.7230\nEpoch 5/10\n1018/1018 [==============================] - 42s 41ms/step - loss: 0.4025 - accuracy: 0.8362 - val_loss: 0.7111 - val_accuracy: 0.7389\nEpoch 6/10\n1018/1018 [==============================] - 42s 41ms/step - loss: 0.3171 - accuracy: 0.8772 - val_loss: 0.7904 - val_accuracy: 0.7287\nEpoch 7/10\n1018/1018 [==============================] - 42s 42ms/step - loss: 0.2400 - accuracy: 0.9124 - val_loss: 0.9459 - val_accuracy: 0.7277\nEpoch 8/10\n1018/1018 [==============================] - 42s 41ms/step - loss: 0.1729 - accuracy: 0.9432 - val_loss: 0.9520 - val_accuracy: 0.7203\nEpoch 9/10\n1018/1018 [==============================] - 42s 42ms/step - loss: 0.1331 - accuracy: 0.9582 - val_loss: 0.9470 - val_accuracy: 0.7436\nEpoch 10/10\n1018/1018 [==============================] - 42s 42ms/step - loss: 0.1071 - accuracy: 0.9684 - val_loss: 1.1690 - val_accuracy: 0.7186\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = range(len(acc))\n\nplt.plot(epochs, acc,'b',label='training acc')\nplt.plot(epochs, val_acc, 'r', label='validation acc')\nplt.legend()\nplt.show()\n\n\nplt.plot(epochs, loss,'b',label='training loss')\nplt.plot(epochs, val_loss, 'r', label='validation loss')\nplt.legend()\nplt.show()","execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'acc' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-2a03e5b5667d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}